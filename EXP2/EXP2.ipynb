{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68040, 32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_file = '/root/autodl-tmp/Multimedia-Experiment/实验二/ColorHistogram.asc'\n",
    "\n",
    "df = pd.read_csv(data_file, header=None, index_col=0, sep=' ')\n",
    "matrix = np.array(df.iloc[:].values)\n",
    "matrix.shape  # (68040, 32)  行向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(a, b):\n",
    "    assert a.shape == b.shape\n",
    "    abs_dif = np.abs(a - b)\n",
    "    mean_dif = np.mean(abs_dif)\n",
    "    max_dif = np.max(abs_dif)\n",
    "    min_dif = np.min(abs_dif)\n",
    "    print(\"mean_dif:{}\".format(mean_dif))\n",
    "    print(\"max_dif:{}\".format(max_dif))\n",
    "    print(\"min_dif:{}\".format(min_dif))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def var(data, bias=False):\n",
    "    # 求一组随机变量方差, data: (n * feature_dim)\n",
    "    vars = []\n",
    "    mean = np.mean(data, axis=0)  # (feature_dim, )\n",
    "    for dim in range(data.shape[1]):\n",
    "        var_dim = np.sum((data.T[dim] - mean[dim]).dot(data.T[dim] - mean[dim]))\n",
    "        if bias:\n",
    "            vars.append(var_dim / data.shape[0])\n",
    "        else:\n",
    "            vars.append(var_dim / (data.shape[0] - 1))\n",
    "    return np.array(vars)\n",
    "\n",
    "\n",
    "def cov(data, bias=False):\n",
    "    cov = []\n",
    "    mean = np.mean(data, axis=0)  # (feature_dim, )\n",
    "    for i in range(data.shape[1]):\n",
    "        for j in range(data.shape[1]):\n",
    "            var_ij = np.sum((data.T[i] - mean[i]).dot(data.T[j] - mean[j]))\n",
    "            if bias:\n",
    "                cov.append(var_ij / data.shape[0])\n",
    "            else:\n",
    "                cov.append(var_ij / (data.shape[0] - 1))\n",
    "    return np.array(cov).reshape(data.shape[1], data.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_dif:1.1570470059493743e-18\n",
      "max_dif:8.673617379884035e-18\n",
      "min_dif:0.0\n"
     ]
    }
   ],
   "source": [
    "from numpy import var as np_var_fuc\n",
    "\n",
    "vars = var(matrix, bias=True)\n",
    "np_var = np_var_fuc(matrix, axis=0)\n",
    "compare(vars, np_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_dif:2.590361324649555e-19\n",
      "max_dif:1.3877787807814457e-17\n",
      "min_dif:0.0\n"
     ]
    }
   ],
   "source": [
    "from numpy import cov as np_cov_func\n",
    "\n",
    "covs = cov(matrix, bias=False)\n",
    "np_covs = np_cov_func(matrix.T, bias=False)\n",
    "compare(covs, np_covs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "&emsp;&emsp;给定列向量 $\\boldsymbol{z}_i\\in \\mathcal{X} \\in \\mathbb{R}^{m\\times 1},i=1,2,\\cdots,n$，我们希望将其降至 $k$ 维。PCA 给出的方法是通过某种 *线性投影*，将高维的数据映射到低维的空间中，并期望在所投影的维度上数据的信息量最大（方差最大），以此使用较少的数据维度，同时保留住较多的原数据点的特性。  \n",
    "&emsp;&emsp;样本集 $D=\\{\\boldsymbol{z}_i\\}_{i=1}^n$ 的均值向量 $\\overline{\\boldsymbol{z}}=\\sum\\limits_{i=1}^n \\boldsymbol{z}_i$，我们先将数据去中心化：$\\boldsymbol{x}_i=\\boldsymbol{z}_i-\\overline{\\boldsymbol{z}}$。其协方差矩阵为：  \n",
    "$$\n",
    "\\boldsymbol{S}=[s_{ij}]_{m\\times m}\\\\\n",
    "s_{ij}=\\frac{1}{n-1}\\sum\\limits_{k=1}^n (\\boldsymbol{x}_{ki}-\\overline{\\boldsymbol{z}}_i)(\\boldsymbol{x}_{kj}-\\overline{\\boldsymbol{z}}_j)=\\frac{1}{n-1}\\sum\\limits_{k=1}^n \\boldsymbol{x}_{ki}\\cdot \\boldsymbol{x}_{kj}\n",
    "$$\n",
    "&emsp;&emsp;所以，$\\boldsymbol{S}=\\frac{1}{n-1}\\boldsymbol{X}\\boldsymbol{X}^T$。  \n",
    "&emsp;&emsp;为了降维，考虑正交线性变换：$\\mathcal{W}\\in \\mathbb{R}^{m\\times k}$，变换后的样本：$\\boldsymbol{y}_i=\\mathcal{W}^T\\boldsymbol{x}_i \\in \\mathbb{R}^{k\\times 1}$，变换矩阵 $\\mathcal{W}$ 可认为由 $k$ 个正交基向量组成：$\\mathcal{W}=(\\boldsymbol{w}_1,\\cdots,\\boldsymbol{w}_k)$，且 $||\\boldsymbol{w}_i||_2=1,\\boldsymbol{w}_i^T\\boldsymbol{w}_j=0,i\\neq j$。变换后的新表示可认为是 $\\boldsymbol{x}$ 与这 $k$ 个正交基向量内积的组合：$\\boldsymbol{x}_i'=(\\boldsymbol{w}_1^T\\boldsymbol{x}_i,\\cdots,\\boldsymbol{w}_k^T\\boldsymbol{x}_i)$。  \n",
    "&emsp;&emsp;延续我们在上文的讨论，我们需要使得该变换后的方差 $\\lambda$ 最大，则在每一维上的方差都应尽可能大。在第 $j<k$ 维上有：  \n",
    "$$\n",
    "\\lambda_j=\\frac{1}{n-1}\\sum\\limits_{i=1}^n (\\boldsymbol{x}_{ij}'-\\overline{\\boldsymbol{x}}_j')^2=\\frac{1}{n-1}\\sum\\limits_{i=1}^n  (\\boldsymbol{x}_{ij}'- \\frac{1}{n-1}\\sum\\limits_{m=1}^n \\boldsymbol{w}_j^T \\boldsymbol{x}_m)^2=\\frac{1}{n-1}\\sum\\limits_{i=1}^n (\\boldsymbol{x}_{ij}')^2=\\frac{1}{n-1}\\sum\\limits_{i=1}^n(\\boldsymbol{w}_j^T\\boldsymbol{x}_i\\boldsymbol{x}_i^T\\boldsymbol{w}_j)=\\frac{1}{n-1}\\boldsymbol{w}_j^T\\boldsymbol{X}\\boldsymbol{X}^T\\boldsymbol{w}_j=\\boldsymbol{w}_j^T \\boldsymbol{S}\\boldsymbol{w}_j\n",
    "$$\n",
    "&emsp;&emsp;同时左乘 $\\boldsymbol{w}_j$，有 $\\lambda_j \\boldsymbol{w}_j=\\boldsymbol{S}\\boldsymbol{w}_j$，所以$\\lambda_i,\\boldsymbol{w}_j$ 分别是协方差矩阵 $\\boldsymbol{S}$ 的特征值与特征向量。 所以很显然，我们取协方差矩阵 $\\boldsymbol{S}$ 的 $k$ 个最大的特征值对应的特征向量，则得到了我们所需要的变换矩阵 $\\mathcal{W}$ 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68040, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_pca(data, k):\n",
    "    X_mean = np.mean(data, axis=0)  # (32,)\n",
    "    data = data - X_mean  # 去均值\n",
    "    ew, ev = np.linalg.eig(data.T.dot(data))  # 特征值与特征向量, ew:(32,), ev:(32, 32)\n",
    "    ew_order = np.argsort(ew)[::-1]  #从大到小\n",
    "    ev_sort = ev[:, ew_order]\n",
    "    feature = ev_sort[:, :k]\n",
    "    new_data = data.dot(feature)\n",
    "    return new_data\n",
    "\n",
    "\n",
    "my_pca_data = my_pca(matrix, k=5)\n",
    "my_pca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.10149526e-02,  9.67559554e-17,  8.60255998e-18,\n",
       "        -3.13295052e-18, -1.02212511e-17],\n",
       "       [ 9.67559554e-17,  2.76484273e-02,  0.00000000e+00,\n",
       "        -1.58997239e-17, -1.25579100e-17],\n",
       "       [ 8.60255998e-18,  0.00000000e+00,  1.93800927e-02,\n",
       "        -9.41843251e-18,  1.56190638e-17],\n",
       "       [-3.13295052e-18, -1.58997239e-17, -9.41843251e-18,\n",
       "         1.57017760e-02,  1.17094026e-17],\n",
       "       [-1.02212511e-17, -1.25579100e-17,  1.56190638e-17,\n",
       "         1.17094026e-17,  1.18432912e-02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pca_cov = cov(my_pca_data, bias=False)\n",
    "my_pca_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(matrix)\n",
    "standard_pca_data = pca.transform(matrix)\n",
    "standard_pca_cov = np_cov_func(standard_pca_data.T, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_dif:1.258848305636457e-10\n",
      "max_dif:8.731390625407442e-10\n",
      "min_dif:7.054773432102479e-14\n"
     ]
    }
   ],
   "source": [
    "compare(my_pca_cov, standard_pca_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_dif:0.11721605390112377\n",
      "max_dif:1.2458614313109861\n",
      "min_dif:1.608102540018308e-12\n"
     ]
    }
   ],
   "source": [
    "compare(my_pca_data, standard_pca_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}